---
title: "Team 3 Group Project"
author: "Jacquelyn Cintron, Mireille Nkamsi, and Ronald Zambrano"
date: "11/24/2019"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

Notes: 
  - You do not have to put all of your team members' code into a single file. I have included all 5 analyses just for your information. You only need the code for your analysis.
  - The tasks include both coding and written interpretation. 
  - Please knit to word document -- it will make it easier to combine your results with your team members in to the single manuscript (submitted in GP4).

## Setup

### Load packages

Add whatever additional packages you need for your analysis

```{r setup, include=FALSE}
### EDIT!!!

### We use the code chunk option "include=FALSE" because we don't need to print this information

### Global knitr options
knitr::opts_chunk$set(echo = TRUE)

### Load packages/libraries that we will need
library(tidyverse)
library(skimr)      # data checking
library(naniar)     # data cleaning
library(janitor)    # data cleaning
library(GGally)     # data viz
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(ggdendro)   # clustering visualization
library(dendextend) # for comparing two dendrograms
library(viridis)       # Better plot colors
library(ggbiplot)      # PCA plot
library(corrr)         # Correlations
library(ggridges)      # Density ridge plot
library(ggpubr)        # Fancy plots
library(psych)         # Distributions
#  edit! Add whatever additional packages you need here (if you haven't loaded them, RMarkdown should alert you when you go to "knit" the RMarkdown to a report)
```


### Custom ggplot theme

So that we don't need to add this code to all ggplots individually. Feel free to use or not use, and to modify however you wish.

```{r theme}
### DON'T EDIT CODE IN THIS CHUNK

theme_custom <- theme_bw() +
  
  # if we have a plot title or subtitle, let's center it
  theme (
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  ) 
theme_set(theme_custom)

### We'll make the viridis color scale our default plotting color palette
scale_colour_continuous <- function(...) {
  scale_colour_viridis_c(...)
}
scale_fill_continuous <- function(...) {
  scale_fill_viridis_c(...)
}
scale_colour_discrete <- function(...) {
  scale_colour_viridis_d(..., begin = 0, end = 0.9)
}
scale_fill_discrete <- function(...) {
  scale_fill_viridis_d(..., begin = 0, end = 0.9)
}
```


### Setwd fix (if needed)

If you are having trouble loading the exprs_tidy file below, manually override the working directory. To do this
  1. In the menu bar, click: Session > Set Working Directory > To Source File Location
  2. Copy the line of code in the console, and paste it into the code chunk below
  
```{r fix_setwd}
### EDIT if necessary
#setwd("~/Documents/School/BIFS613/BIFS613- Group Project")
```


### FYI: how I got the data

```{r get_data, eval=FALSE}
### Get list of available datasets
### https://www.bioconductor.org/packages/3.3/bioc/vignettes/TCGAbiolinks/inst/doc/tcgaBiolinks.html#harmonized-data-1
View(getGDCprojects())

### Datasets to use for group project (I picked the ones with smallest sample size and no sex bias)
projects <- c(
  "TCGA-ACC",
  "TCGA-CHOL", 
  "TCGA-DLBC", 
  "TCGA-KICH", 
  "TCGA-MESO", 
  "TCGA-UVM"
)

phenoList <-  vector(mode = "list", length = length(projects))
names(phenoList) <- projects
exprsList <-  vector(mode = "list", length = length(projects))
names(exprsList) <- projects
for (i in projects) { 
  ### Get data (in summarized experiment ["se"]  format)
  query <- GDCquery(
    project = i, 
    data.category = "Transcriptome Profiling", 
    data.type = "Gene Expression Quantification", 
    workflow.type = "HTSeq - FPKM"
  )
  GDCdownload(query)
  se <- GDCprepare(query)
  
  ### Extract phenoData and remove columns that either are all different or all consistent
  pheno_full <- as.data.frame(colData(se))
  pheno <- janitor::remove_constant(pheno_full)
  
  ### Extract exprs matrix and remove lowly expressed
  exprs_full <- assay(se)
  keep <- rowSums(exprs_full > 1) >= 10
  exprs <- exprs_full[keep, ]

  ### Shorten the sample id
  rownames(pheno) <- abbreviate(gsub("TCGA-OR-", "", rownames(pheno)), method = "both")
  pheno$id <- rownames(pheno)
  colnames(exprs) <- abbreviate(gsub("TCGA-OR-", "", colnames(exprs)), method = "both")
  
  ### Remove extra columns (not groups)
  pheno$sample <- pheno$id
  pheno$id <- NULL
  remove_cols <- c(
    "patient", "updated_datetime", "updated_datetime.x", "updated_datetime.y", 
    "barcode", "diagnosis_id", "demographic_id", "exposure_id", "bcr_patient_barcode", 
    "morphology", "treatments", 
    "days_to_birth", "days_to_last_follow_up", "days_to_death",
    "year_of_birth", "year_of_diagnosis", "year_of_death"
  )
  pheno <- pheno[ , !(colnames(pheno) %in% remove_cols)]
  pheno <- pheno[ , !(colnames(pheno) %in% colnames(pheno)[grep("_CHOL_del|_CHOL_amp|subtype_", colnames(pheno))])]

  ### Save
  saveRDS(exprs, paste0(i, "_exprs.rds"))
  saveRDS(pheno, paste0(i, "_pheno.rds"))
  
  ### Add to list
  exprsList[[i]]  <- exprs
  phenoList[[i]] <- pheno
  
  ### Clean up
  rm(exprs)
  rm(exprs_full)
  rm(pheno)
  rm(pheno_full)
  rm(keep)
}

### Save
saveRDS(exprsList, "all_exprs.rds")
saveRDS(phenoList, "all_pheno.rds")

### Look at
sapply(exprsList, dim)
sapply(phenoList, dim)
sapply(phenoList, names)

### Write out names
rbind(
  paste("ACC:", toString(sort(names(phenoList$`TCGA-ACC`)))),
  paste("CHOL:", toString(sort(names(phenoList$`TCGA-CHOL`)))),
  paste("DLBC:", toString(sort(names(phenoList$`TCGA-DLBC`)))),
  paste("KICH:", toString(sort(names(phenoList$`TCGA-KICH`)))),
  paste("MESO:", toString(sort(names(phenoList$`TCGA-MESO`)))),
  paste("UVM:", toString(sort(names(phenoList$`TCGA-UVM`))))
) %>%
  writeLines("sample_variables.txt")
```


## [EDIT AS TEAM] Pre-process data 

Your entire team should use the same code for this section!

### Load your dataset [edit!]

```{r load_data}
### EDIT: You need to insert your dataset file names in the quotes below

exprs <- readRDS(
  "TCGA-DLBC_exprs.rds"     # EDIT: insert your *_exprs.rds dataset's file name here
)
pheno <- readRDS(
  "TCGA-DLBC_pheno.rds"     # EDIT: insert your *_pheno.rds dataset's file name here
)
```

### Pick your group (variable of interest) [edit!]

This should be a variable that is categorical with at least 2 categories and at least 3 samples in each category Use colnames(pheno) to find out what variable options you have. You can use one of the descriptive summary functions (from AE3) to determine how many categories there are for each group, and how many samples there are for each category.

```{r select_group}
### EDIT!! Copy your variable of interest into a new column called "group". This will help generalize/simplify your project's code

pheno$group <- pheno$ann_arbor_b_symptoms  # EDIT: insert your variable's column name here
```

### Convert expression matrix to tidy 

```{r tidy}
### Don't edit 

### Create tibble with expression and pheno data
tidy <- exprs %>% 
  
  # Convert expression matrix to tidy tibble
  as_tibble(rownames = "gene") %>%
  gather("sample", "fpkm", -gene)  %>%

  # Add phenoData
  inner_join(pheno, by = "sample")
```

### Filter samples [edit if appropriate]

Check for samples with missing data for your "group"

```{r filter_samples 1}
### Don't edit

### You can check this using the following (many other ways to check too)
### Make sure no "blanks" either -- 
### sometimes missing data isn't converted to an NA but instead is just blank
summary(as.factor(tidy$group)) # look for blanks, no data, etc. categories
table(is.na(tidy$group))
```

Remove samples with missing data (or no data; i.e. "not reported") for your "group"

```{r filter_samples 2}
### EDIT (if you have any samples with NA or blank for your group)

tidy <- tidy %>% 
  filter(
    
    # EDIT: add filter(s) here to remove NAs and samples with no data, below are common examples of how missing data is listed in phenoData. Make sure you don't need any additional filters to remove missing data for your "group"
    
    group != "not reported",    # some samples may have missing data listed as "not reported"
    !is.na(group),              # some may have missing data listed as NA
    group != ""                 # some may have blanks
    
  )
```

### Convert back to matrix (some analyses use matrices rather than tidy data)

```{r matrices}
### Don't edit

### Convert expression data to wide/matrix
exprs_mat <- tidy %>%
  select(gene, sample, fpkm) %>%
  spread(sample, fpkm, fill = 0) %>%
  column_to_rownames("gene") %>%
  as.matrix()

### Convert phenoData to wide table
pheno_mat <- tidy %>%
  select(-one_of(c("gene", "fpkm"))) %>%
  distinct() %>%
  data.frame()
rownames(pheno_mat) <- pheno_mat$sample

### Fix order of samples, so they match
table(colnames(exprs_mat) == rownames(pheno_mat)) # check
pheno_mat <- pheno_mat[order(rownames(pheno_mat), colnames(exprs_mat)), ] # fix
table(colnames(exprs_mat) == rownames(pheno_mat)) # check
```

### Filter genes

Here, we'll only keep genes that are expressed at >= 1 FPKM in at least 20 samples.

```{r filter_genes_fixed}
### Don't edit

### Count # genes pre-filtering
nrow(exprs_mat)

exprs_mat <- exprs_mat[rowSums(exprs_mat > 1) > 20, ]

### Count # genes post-filtering
nrow(exprs_mat)
```

## [one team member does this] Team Member #1 (Ronald Zambrano): Descriptive sample summary statistics

Tasks:
  a. Table summarizing phenoData, stratified by the categories in your group of interest, this should also include missing data
  b. Determine statistically significant differences, using appropriate statistical tests (based on whether the value is continuous vs. discrete, how many groups are being tested, and whether the groups have equal variances)
  c. Briefly describe the origin/source of the data (tumor type, the RNA-Seq performed to generate the expression data).
  d. Describe the sample dataset using the summary table and statistical test results

[enter code here, see AE3 to get started!]

### a. Table summarizing phenoData, stratified by the categories in your group of interest, this should also include missing data
```{r Descriptive sample summary statistics A}

phenoData <- pheno %>%
  # stratify categories of interest
  select(ann_arbor_b_symptoms, age_at_index) 
  
  # print table of pheno data
  table(phenoData)
  
  # print percentage of ann arbor b symptoms
  janitor::tabyl(phenoData$ann_arbor_b_symptoms)
  
  # print percentage of age at index
  janitor::tabyl(phenoData$age_at_index)
  
  # print summary table of pheno data
  summary(phenoData)

```


### b. Determine statistically significant differences, using appropriate statistical tests (based on whether the value is continuous vs. discrete, how many groups are being tested, and whether the groups have equal variances)
```{r Descriptive sample summary statistics B}

  # remove NAs so that statistics functions don't bug out
  phenoData <- phenoData %>%
    filter(!is.na(ann_arbor_b_symptoms))

  # convert ann_arbor_symptoms to factor rather than the default character assignation
  phenoData$ann_arbor_b_symptoms <- forcats::as_factor(phenoData$ann_arbor_b_symptoms)

  # print skim summary statistics
  phenoData %>%
    group_by(ann_arbor_b_symptoms) %>%
    skim(age_at_index)

  # print ggplots for ann arbor b symptoms and age at index
  phenoData %>%
    select(ann_arbor_b_symptoms, age_at_index ) %>%
    ggpairs()
  
  # descriptive statistics of pheno data
  describe(phenoData)

  # descriptive statistics of age at index by ann arbor b symptoms
  describeBy(phenoData, group = phenoData$ann_arbor_b_symptoms)
  
### Significantly different age in the groups?
  t.test(pheno$age_at_diagnosis ~ pheno$ann_arbor_b_symptoms)

```

### c. Briefly describe the origin/source of the data (tumor type, the RNA-Seq performed to generate the expression data).
```{r Descriptive sample summary statistics C}
# The source of our data was taken from DLBLC lymphoma tissue biopsy samples which were collected from patient lymph nodes primarily, but also from nervous system tissue, digestive tract, glands, and more. The DLBCL gene expression dataset has over 14,000 recorded gene expression levels from the aformentioned DLBCL tissue biopsies. Aligned sequencing reads for RNA (RNA-Seq) were primarily performed on the Illumina platform.
```


### d. Describe the sample dataset using the summary table and statistical test results
```{r Descriptive sample summary statistics D}
  # Descriptive sample statistics anlyses highlighted some key similarites and differences between patient's exhibiting ann arbor b symptoms, and those who did not at the time of index. Overall, in 76% of the valid samples the patients did not exhibit Ann Arbor B symptoms. The average age of the patient who provided the tissue is 56.27 years. Now, when comparing within groups, several differences stand out besides the difference in count. The mean age for patients with symptoms was older, 58.45 in sympotomatic patients versus 55.2 in asymptomatic patients. Despite there being patients from the age of 23 to 82, the youngest age in which patients exhibited ann arbor b symptoms was 42 years. Additionally, when looking at each ann arbor b symptom group's kurtosis, symptomatic patients had a significantly left leaning distribution with a kurtosis of -1.54 versus -0.79, meaning it has a lighter tails than normal distribution.
```






## Team Member #2: Distribution

### Prepare data

```{r}
### Calculate log2(FPKM)
tidy$logFPKM <- log2(tidy$fpkm + 0.00001) # add small value to prevent the "-Inf" caused by log2(0)
```

###  a. Generate histogram, frequency plot, density plot, and density ridge plot of expression values for each category in your group of interest

Note from Alexis: You almost had this part. The error you had was plotting by sample for color/fill instead of by group.

Histogram

```{r histogram}
tidy %>%
  ggplot(aes(x = logFPKM, color = group, fill = group)) +
  geom_histogram(alpha = 0.2)
ggsave("histogram.png")
```

Frequency plot

```{r frequency_plot}
tidy %>%
  ggplot(aes(x = logFPKM,  color = group, fill = group)) +
  geom_freqpoly()
ggsave("freqplot.png")
```

Density plot

```{r density_plot}
tidy %>%
  ggplot(aes(x = logFPKM,  color = group, fill = group)) +
  geom_density(alpha = 0.2)
ggsave("density.png")
```

Density ridge plot with mean and median indicated

```{r density_mean}
### DON'T EDIT CODE IN THIS CHUNK

### Add mean and median to our ridges plot
tidy %>%
  ggplot(aes(x = logFPKM,  y = group, color = group, fill = group)) +
  geom_density_ridges(alpha = 0.2, show.legend = FALSE) +

  # Add mean as line
  ggpubr::stat_central_tendency(
    type = "mean", 
    geom = "line",
    show.legend = FALSE
  ) +

  # Add median as triange at bottom
  ggpubr::stat_central_tendency(
    type = "median", 
    geom = "point", size = 5, shape = 17, 
    show.legend = FALSE
  ) 
ggsave("ridges_means_medians.png")
```

###  b. Decide which best illustrates your distributions

Add this sentence to the results section. (I suggest using the density plot with means and medians)

###  c. Generate a final distribution figure to include in the manuscript

Use the figure that you describe in b.

###  d. Indicate the mean and median in the figure, for each category in your group of interest

See the density ridge plot above.

###  e. Determine distribution shapes (skewedness, kurtosis)

Add intepretation of the results below to the results section. 

```{r dist_shape}
### Normality: Skewed/Kurtosis-peaked-vs-normal-distribution
shapes <- lapply(unique(tidy$group), function (x) {
  describe(tidy$logFPKM[tidy$group == x])
}) 
cbind.data.frame("group" = unique(tidy$group), bind_rows(shapes))
```

## Team Member #3: Hierarchical clustering

Tasks:
  a. Determine ideal clustering methods (including # clusters)
  b. Generate a final figure of the clustering
  c. Provide table summarizing the number of samples in each cluster and the breakdown of samples by your group of interest
  d. Interpret the clustering results

### Prepare data

```{r hc_prep}
### Check for missing/infinite data
table(is.na(exprs))

### Transpose matrix so that we're clustering samples (not genes)
exprs_mat <- t(exprs)

### Log transform
exprs_mat <-log(exprs_mat + 0.0001, base = 2)

### Scale
set.seed(1234)
exprs_mat <- scale(exprs_mat)
```

### Compare HC methods

```{r hc_options}
### Vector of all HC methods that agnes() allows
agnes_methods <- c("average", "single", "complete", "ward", "weighted")
```
```{r hc_method}
### Try all combinations
for (i in agnes_methods) {
  
  # Reproducibility
  set.seed(1234)

  # Run 
  hc <- exprs_mat %>%
    agnes(method = i, metric = "euclidean")
  
  # Plot
  plot_hc <- hc %>%
    as.dendrogram() %>%
    ggdendrogram(rotate = FALSE, size = 2) +
    
    # Title includes hc method used
    # and the agglomerative coefficient (rounded to 2 decimals)
    ggtitle(paste("HC:", i, round(hc$ac, 2))) 

  # Print plot
  print(plot_hc)
  
  # Save plot
  ggsave(paste0("hc_plot_", i, ".png"))
}
```

### Choose optimal HC method

[update based on prev] (the HC method above with the highest agglomerative coefficient)

```{r hc_method_final}
final_hc_method <- "ward"
```

### Compare distance methods for final HC method

```{r hc_final_dist}
### Run
dend_euc <- exprs_mat %>%
  agnes(method = final_hc_method, metric = "euclidean") %>%
  as.dendrogram()
dend_man <- exprs_mat %>%
  agnes(method = final_hc_method, metric = "manhattan") %>%
  as.dendrogram()

### Plot together
dend_list <- dendlist(dend_euc, dend_man)
tanglegram(
  dend_euc, dend_man,
  highlight_distinct_edges = FALSE,       # Turn-off dashed lines
  common_subtrees_color_lines = FALSE,    # Turn-off line colors
  common_subtrees_color_branches = TRUE,  # Color common branches 
  main = paste(
    "entanglement =", 
    round(entanglement(dend_list), 2)
  )
)
ggsave("tanglegram.png")
```

### Determining optimal clusters

Method 1: WSS ("elbow") method

```{r hc_wss}
set.seed(1234)
fviz_nbclust(exprs_mat, FUN = hcut, method = "wss")
ggsave("hc_wss_plot.png")
```

Method: Gap Statistic Method

```{r hc_gap}
set.seed(1234)
fviz_nbclust(exprs_mat, FUN = hcut, nboot = 50, method = "gap_stat")
ggsave("hc_gapstat_plot.png")
```

[update based on prev] Set optimal # clusters

```{r hc_final_cluster}
n_clust <- 2
```

### Final HC result 

```{r hc_final}
### Calculate HC
hc_final <- agnes(exprs_mat, method = final_hc_method, metric = "euclidean")

### Cut tree
hc_final_clusters <- cutree(hc_final, k = n_clust)

### View tree 
clust.df <- data.frame(
  label = names(hc_final_clusters), 
  cluster = factor(hc_final_clusters)
)
dendr <- as.ggdend(as.dendrogram(hc_final))
dendr[["labels"]] <- merge(
  dendr[["labels"]], 
  clust.df, 
  by = "label"
)
ggplot() + 
  geom_segment(
    data = segment(dendr), 
    aes(x = x, y = y, xend = xend, yend = yend)
  ) + 
  
  # Label clusters
  geom_text(
    data = label(dendr), 
    aes(x, y, label = label, color = cluster), 
    size = 3, hjust = 0
  ) +
  
  # Flip axes
  coord_flip() + 
  
  # Formating
  scale_y_reverse(expand = c(0.2, 0)) + 
  theme_classic() +
  theme(
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank(),
    axis.title = element_blank()
  )
ggsave("hc_dendro.png")
```

### Summarize cluster assignments by group

Add cluster assignments to phenoData

```{r}
### Add column for HC clusters
res_clusters <- pheno %>%
  mutate(
    hc_cluster = paste0("cluster_", hc_final_clusters)
  )
```

As table

```{r}
### Get absolute number of samples in each cluster by group
res_clusters %>%
  select(group, hc_cluster) %>% 
  table()
```

[update based on prev] As figure

```{r}
### Visualize percent of samples in each cluster by group
res_clusters %>%
  
  # Get percent of samples in each group in each cluster
  dplyr::group_by(group, hc_cluster) %>% 
  dplyr::summarise(n = n()) %>%
  spread(hc_cluster, n) %>%
  mutate(n_samples = sum(cluster_1, cluster_2, na.rm = TRUE)) %>%
  mutate(
    cluster_1 = round(100*cluster_1/n_samples),
    cluster_2 = round(100*cluster_2/n_samples)
  ) %>%
  select(group, n_samples, dplyr::everything()) %>%
  gather(cluster, percent, -group, -n_samples) %>%
  
  # Plot
  ggplot(aes(x = cluster, y = group, fill = percent)) +
  geom_tile() +
  
  # Formatting
  theme_classic() +
  ggtitle(paste0("Clustering by Group (", n_clust, " clusters)")) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0))
ggsave("hc_cluster_tile.png")
```

## Team Member #4: PCA
Tasks: a. Generate scree plot with Kaiser cutoff line b. Determine number of PCs to use, using Kaiser cutoff c. Generate PCA biplots for those PCs d. Perform network correlation of PCs and sample pheno data e. Interpret clustering patterns and relationship of PCs and pheno data to your group of interest using the PC biplots and correlation network plot

```{r Prepare data}
### Log transform
exprs_mat <- log2(exprs + 0.0001)
### Transpose so that we're clustering samples (not genes)
exprs_mat <- t(exprs_mat)
```

```{Run PCA}
set.seed(1116)
pca_obj <- prcomp(
  exprs_mat, 
  scale. = TRUE, 
  center = TRUE
)
###Summary
summary(pca_obj)

##Scree plot
Comment from Alexis: the Kaiser cutoff is the horizontal line at 0.1, not the total number of PCs identified. So the cutoff is at PC2 not PC46.
### Calculate variance explained (ve) for each PC
ve <- pca_obj$sdev^2 
### Create table (dataframe called "ve") of variance explained measures (using SD values), so we can plot them
df_ve <- data.frame(
  PC = as_factor(1:length(ve)),    # PC 
  PVE = ve / sum(ve)               # proportion ve
) 
### Plot
df_ve %>%
  ggplot(aes(x = PC, y = PVE, fill = PC)) + 
  geom_col(show.legend = FALSE) +
  
  # add kaiser criterion line
  geom_hline(yintercept = 0.1) +
  
  # add plot title
  labs(title = "Scree plot")

### Biplot for PC1 vs. PC2
pca_obj %>% 
  ggbiplot(
    choices = 1:2, 
    groups = pheno$group,
    ellipse = TRUE,
    var.axes = FALSE
  ) 
 
pca_obj %>% 
  ggbiplot(
    choices = 1:2, 
    groups = pheno$group,
    labels = pheno$sample,
    labels.size = 3,
    ellipse = TRUE,
    var.axes = FALSE
  ) 
 
####Correlate PCs to phenoData (known sample variables)

#### Run
### PC results to phenoData
pca_obj_pheno <- pheno %>%
  
  # Just some phenoData variables 
  select(
    group, age_at_diagnosis, gender, race,
    ann_arbor_clinical_stage, ann_arbor_b_symptoms,
    ann_arbor_extranodal_involvement,
    site_of_resection_or_biopsy
  ) %>%
  
  # Just the first 5 PCs (so the first 5 columns)
  # First need to convert the pca results from matrix to tibble/data.frame
  bind_cols(as_tibble(pca_obj$x[ , 1:5]))
### Convert non-numberic values (characters, factors) to numberic values
for (i in names(pca_obj_pheno)) {
  if(is.factor(pca_obj_pheno[[i]])) {
    pca_obj_pheno[[i]] <- as.numeric(pca_obj_pheno[[i]])
  }
  if(is.character(pca_obj_pheno[[i]])) {
    pca_obj_pheno[[i]] <- as.numeric(as.factor(pca_obj_pheno[[i]]))
  }
}
### Run correlation
set.seed(1116)
pca_corr <- pca_obj_pheno %>%
  correlate(method = "pearson") 
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'

#### Barplot
### Plot
pca_corr %>% 
  # "focusing" on group of interest
  focus(group) %>%
  
  # "gather" (create a single column) of phenoData variables ("vars")
  # with their pearson's correlation ("value") for each PC in second column
  # rowname = PC#
  gather(var, value, -rowname) %>%
  
  # Plot
  ggplot(aes(rowname, value, color = var, fill = var)) +
  geom_col(position = "dodge") +
  coord_flip() +
  labs( 
    x = NULL, # Remove 
    y = "Pearson's correlation",
    title = "Correlation of sample information to the first five PCs"
  ) +
  scale_y_continuous(limits = c(-1, 1))
 
#### Network plot
network_plot(pca_corr)
``` 

## Session info

```{r sessioninfo}
sessionInfo()
```
